# Sign-Language-Fingerspelling-Assistant-ASL-Alphabet-Project-
American Sign Language (ASL) Fingerspelling Recognition System
------------------------------------------------
![image](https://github.com/Salma-Salah420/Sign-Language-Fingerspelling-Assistant-ASL-Alphabet-Project-/blob/ea2349c99e3a9b73bc38ddb292f5a5903cd31788/ASLAlphabet-3.jpg)

------------------------------
 Project Objective:
 -------------------
Develop an intelligent deep learning system that recognizes and translates American Sign Language (ASL) alphabet gestures from images and real-time video into text, promoting accessibility and communication for the deaf and hard-of-hearing community.
----------------------

üìä Dataset & Problem Statement:
-------------------------------
Dataset: ASL Alphabet Dataset with 87,000 images (29 classes: A-Z, space, delete, nothing)

Classes: 26 letters (A-Z) + 3 special gestures (space, delete, nothing)

Challenge: Real-time recognition of dynamic hand gestures with varying lighting, backgrounds, and hand orientations

Real-world Impact: Bridge communication gap between ASL users and non-signers.
-------------------------------------

üèóÔ∏è Technical Architecture:
1.Model Development 
2.Preprocessing Pipeline:
-Hand Segmentation: MediaPipe Hands for robust hand detection.
-Data Augmentation.
3.Model Evaluation 
Performance Metrics
Architecture Comparison Table
4.Grad-CAM Visualization
5.GUI Implementation
6.Real-time Sentence Builder
----------------------------------
Roles:
